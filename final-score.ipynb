{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification, set_seed\nimport torch\nimport numpy as np\nimport pandas as pd\nimport time\nfrom datasets import load_dataset\nfrom kaggle_secrets import UserSecretsClient\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\nfrom huggingface_hub import login\nfrom torch.profiler import profile, ProfilerActivity\n\n\n# Set seed for reproducibility\nset_seed(42)\n\n# Huggingface login for token\nuser_secrets = UserSecretsClient()\nHuggingface = user_secrets.get_secret(\"Huggingface\")\nlogin(token=Huggingface)\n\ndef evaluate_roberta(metrics,new_dataset, model, tokenizer, labels, language, batch_size=16, device='cuda'):\n    model.to(device)\n\n    # Prepare data\n    texts = new_dataset['combo']\n    true_labels = np.array(new_dataset['labels'])\n\n    # Tokenize the inputs\n    inputs = tokenizer(texts, truncation=True, padding=True, return_tensors=\"pt\")\n    input_ids = inputs['input_ids'].to(device)\n    attention_mask = inputs['attention_mask'].to(device)\n\n    # Split into batches\n    num_batches = (len(texts) + batch_size - 1) // batch_size\n    predictions = []\n    total_time = 0\n    total_flops = 0  # To accumulate FLOPs\n\n    # Perform inference in batches with FLOPs profiling\n    for i in range(num_batches):\n        batch_input_ids = input_ids[i * batch_size: (i + 1) * batch_size]\n        batch_attention_mask = attention_mask[i * batch_size: (i + 1) * batch_size]\n\n        with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], with_flops=True) as p:\n            with torch.no_grad():\n                begin = time.time()\n                outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask)\n                logits = outputs.logits\n                preds = (logits.sigmoid() > 0.5).int().cpu().numpy()\n                total_time += time.time() - begin\n\n        # Accumulate FLOPs for the batch\n        total_flops += sum(k.flops for k in p.key_averages() if k.flops is not None)\n        predictions.append(preds)\n\n    # Concatenate predictions\n    predictions = np.vstack(predictions)\n\n    # Evaluate metrics for each label\n    for i, label in enumerate(labels):\n        tp = np.sum((true_labels[:, i] == 1) & (predictions[:, i] == 1))\n        fp = np.sum((true_labels[:, i] == 0) & (predictions[:, i] == 1))\n        fn = np.sum((true_labels[:, i] == 1) & (predictions[:, i] == 0))\n        tn = np.sum((true_labels[:, i] == 0) & (predictions[:, i] == 0))\n\n        precision = tp / (tp + fp) if tp + fp > 0 else 0\n        recall = tp / (tp + fn) if tp + fn > 0 else 0\n        f1 = (2 * precision * recall) / (precision + recall) if precision + recall > 0 else 0\n\n        metrics.append({'language': language, 'label': label, 'precision': precision, 'recall': recall, 'f1': f1})\n\n    # Calculate average time and GFLOPs\n    # print(pd.DataFrame(metrics))\n    average_time = total_time / len(texts)\n    print(\"Avg runtime in seconds:\", average_time)\n    average_GFLOPs = (total_flops / 1e9)/len(texts)\n    print(\"Average GFLOPs:\", average_GFLOPs)\n    return average_time,average_GFLOPs\n\n\n# Languages and labels\nlangs = ['java', 'python', 'pharo']\nlabels = {\n    'java': ['summary', 'Ownership', 'Expand', 'usage', 'Pointer', 'deprecation', 'rational'],\n    'python': ['Usage', 'Parameters', 'DevelopmentNotes', 'Expand', 'Summary'],\n    'pharo': ['Keyimplementationpoints', 'Example', 'Responsibilities', 'Classreferences', 'Intent', 'Keymessages', 'Collaborators']\n}\n\nds = load_dataset('NLBSE/nlbse25-code-comment-classification')\nmetrics = []\naverage_time = 0\naverage_GFLOPS = 0\nfor lan in langs:\n    tokenizer = AutoTokenizer.from_pretrained(f\"MushfiqurRR/NLBSE-{lan.capitalize()}-final\")\n    model = AutoModelForSequenceClassification.from_pretrained(f\"MushfiqurRR/NLBSE-{lan.capitalize()}-final\")\n    test_data = ds[f'{lan}_test']\n    labels_data = labels[f'{lan}']\n    A_T,A_GF = (evaluate_roberta(metrics,test_data,model,tokenizer,labels_data,lan))\n    average_time+=A_T\n    average_GFLOPS+= A_GF\n    torch.cuda.empty_cache()\nmetrics = pd.DataFrame(metrics)\nmetrics.reset_index(drop=True, inplace=True)\nprint(metrics)\navg_f1 = metrics['f1'].mean()\n# print(average_time)\n# print(average_GFLOPS)\nmax_avg_flops = 5000\nmax_avg_runtime = 5\ndef score(avg_f1, avg_runtime, avg_flops):\n    return (0.6 * avg_f1 +\n      0.2 * ((max_avg_runtime - avg_runtime) / max_avg_runtime) +\n      0.2 * ((max_avg_flops - avg_flops) / max_avg_flops))\nprint(round(score(avg_f1, average_time, average_GFLOPS), 2))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-11T08:13:52.201039Z","iopub.execute_input":"2024-12-11T08:13:52.201459Z","iopub.status.idle":"2024-12-11T08:17:31.950231Z","shell.execute_reply.started":"2024-12-11T08:13:52.201422Z","shell.execute_reply":"2024-12-11T08:17:31.949053Z"}},"outputs":[{"name":"stdout","text":"Avg runtime in seconds: 0.0866441339686297\nAverage GFLOPs: 309.265448448\nAvg runtime in seconds: 0.005903605169850617\nAverage GFLOPs: 22.351215727\nAvg runtime in seconds: 0.010901392537417296\nAverage GFLOPs: 33.223759013\n   language                    label  precision    recall        f1\n0      java                  summary   0.904488  0.881166  0.892675\n1      java                Ownership   1.000000  1.000000  1.000000\n2      java                   Expand   0.439252  0.460784  0.449761\n3      java                    usage   0.921951  0.877030  0.898930\n4      java                  Pointer   0.806452  0.951087  0.872818\n5      java              deprecation   0.818182  0.600000  0.692308\n6      java                 rational   0.268293  0.323529  0.293333\n7    python                    Usage   0.793388  0.793388  0.793388\n8    python               Parameters   0.852459  0.812500  0.832000\n9    python         DevelopmentNotes   0.428571  0.292683  0.347826\n10   python                   Expand   0.683333  0.640625  0.661290\n11   python                  Summary   0.688172  0.780488  0.731429\n12    pharo  Keyimplementationpoints   0.733333  0.511628  0.602740\n13    pharo                  Example   0.921739  0.890756  0.905983\n14    pharo         Responsibilities   0.585714  0.788462  0.672131\n15    pharo          Classreferences   0.500000  0.750000  0.600000\n16    pharo                   Intent   0.843750  0.900000  0.870968\n17    pharo              Keymessages   0.739130  0.790698  0.764045\n18    pharo            Collaborators   0.454545  0.500000  0.476190\n0.8\n","output_type":"stream"}],"execution_count":18}]}